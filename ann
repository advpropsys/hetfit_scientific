digraph {
	graph [size="12.75,12.75"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	11161973712 [label="
 (800, 2)" fillcolor=darkolivegreen1]
	10867412848 [label=AddmmBackward0]
	11111794144 -> 10867412848
	11161651056 [label="layer6.bias
 (2)" fillcolor=lightblue]
	11161651056 -> 11111794144
	11111794144 [label=AccumulateGrad]
	11156098064 -> 10867412848
	11156098064 [label=AddmmBackward0]
	10839866384 -> 11156098064
	11161660096 [label="layer5.bias
 (8)" fillcolor=lightblue]
	11161660096 -> 10839866384
	10839866384 [label=AccumulateGrad]
	10839854240 -> 11156098064
	10839854240 [label=AddmmBackward0]
	11099663488 -> 10839854240
	11161664976 [label="layer4.bias
 (16)" fillcolor=lightblue]
	11161664976 -> 11099663488
	11099663488 [label=AccumulateGrad]
	11099663824 -> 10839854240
	11099663824 [label=NativeBatchNormBackward0]
	11153520192 -> 11099663824
	11153520192 [label=AddmmBackward0]
	11153514000 -> 11153520192
	11161663616 [label="layer3.bias
 (32)" fillcolor=lightblue]
	11161663616 -> 11153514000
	11153514000 [label=AccumulateGrad]
	11153518224 -> 11153520192
	11153518224 [label=AddmmBackward0]
	11153521200 -> 11153518224
	11161649696 [label="layer2.bias
 (16)" fillcolor=lightblue]
	11161649696 -> 11153521200
	11153521200 [label=AccumulateGrad]
	11153518128 -> 11153518224
	11153518128 [label=TanhBackward0]
	11153513616 -> 11153518128
	11153513616 [label=AddmmBackward0]
	11153510832 -> 11153513616
	11161655616 [label="input.bias
 (8)" fillcolor=lightblue]
	11161655616 -> 11153510832
	11153510832 [label=AccumulateGrad]
	11153512416 -> 11153513616
	11153512416 [label=TBackward0]
	11153512128 -> 11153512416
	11087270016 [label="input.weight
 (8, 2)" fillcolor=lightblue]
	11087270016 -> 11153512128
	11153512128 [label=AccumulateGrad]
	11153508528 -> 11153518224
	11153508528 [label=TBackward0]
	11153512656 -> 11153508528
	11161651536 [label="layer2.weight
 (16, 8)" fillcolor=lightblue]
	11161651536 -> 11153512656
	11153512656 [label=AccumulateGrad]
	11153519856 -> 11153520192
	11153519856 [label=TBackward0]
	11153517312 -> 11153519856
	11161661056 [label="layer3.weight
 (32, 16)" fillcolor=lightblue]
	11161661056 -> 11153517312
	11153517312 [label=AccumulateGrad]
	11153506896 -> 11099663824
	11161663456 [label="batchnorm.weight
 (32)" fillcolor=lightblue]
	11161663456 -> 11153506896
	11153506896 [label=AccumulateGrad]
	11153518608 -> 11099663824
	11161653376 [label="batchnorm.bias
 (32)" fillcolor=lightblue]
	11161653376 -> 11153518608
	11153518608 [label=AccumulateGrad]
	11153515392 -> 10839854240
	11153515392 [label=TBackward0]
	11153515152 -> 11153515392
	11161660336 [label="layer4.weight
 (16, 32)" fillcolor=lightblue]
	11161660336 -> 11153515152
	11153515152 [label=AccumulateGrad]
	10839852176 -> 11156098064
	10839852176 [label=TBackward0]
	11153520912 -> 10839852176
	11161656096 [label="layer5.weight
 (8, 16)" fillcolor=lightblue]
	11161656096 -> 11153520912
	11153520912 [label=AccumulateGrad]
	11156923936 -> 10867412848
	11156923936 [label=TBackward0]
	11099668288 -> 11156923936
	11161662816 [label="layer6.weight
 (2, 8)" fillcolor=lightblue]
	11161662816 -> 11099668288
	11099668288 [label=AccumulateGrad]
	10867412848 -> 11161973712
}
